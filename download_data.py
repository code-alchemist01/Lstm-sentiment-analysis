#!/usr/bin/env python3
"""
IMDB Movie Reviews Sentiment Analysis Dataset Ä°ndirme
GPU: RTX 5060 8GB iÃ§in optimize edilmiÅŸ
"""

import os
import kaggle
import pandas as pd
import torch
from pathlib import Path
from datasets import load_dataset

def download_imdb_dataset():
    """IMDB movie reviews datasetini indir"""
    
    # Veri klasÃ¶rÃ¼nÃ¼ oluÅŸtur
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    print("ğŸ”„ IMDB Movie Reviews dataset indiriliyor...")
    
    try:
        # Kaggle'dan IMDB dataset indir
        kaggle.api.dataset_download_files(
            'lakshmi25npathi/imdb-dataset-of-50k-movie-reviews',
            path='./data',
            unzip=True
        )
        print("âœ… Kaggle'dan IMDB dataset indirildi!")
        
        # CSV dosyasÄ±nÄ± oku
        df = pd.read_csv('./data/IMDB Dataset.csv')
        
    except Exception as e:
        print(f"âš ï¸  Kaggle'dan indirme baÅŸarÄ±sÄ±z: {e}")
        print("ğŸ”„ Hugging Face'den IMDB dataset indiriliyor...")
        
        # Alternatif: Hugging Face datasets
        dataset = load_dataset("imdb")
        
        # Train ve test setlerini DataFrame'e Ã§evir
        train_df = pd.DataFrame(dataset['train'])
        test_df = pd.DataFrame(dataset['test'])
        
        # BirleÅŸtir
        df = pd.concat([train_df, test_df], ignore_index=True)
        df.columns = ['review', 'sentiment']
        df['sentiment'] = df['sentiment'].map({0: 'negative', 1: 'positive'})
        
        # CSV olarak kaydet
        df.to_csv('./data/IMDB Dataset.csv', index=False)
        print("âœ… Hugging Face'den IMDB dataset indirildi!")
    
    print(f"ğŸ“Š Total samples: {len(df)}")
    print(f"ğŸ“Š Positive reviews: {len(df[df['sentiment'] == 'positive'])}")
    print(f"ğŸ“Š Negative reviews: {len(df[df['sentiment'] == 'negative'])}")
    
    # Ã–rnek verileri gÃ¶ster
    print("\nğŸ“ Ã–rnek veriler:")
    print(df.head())
    
    return df

def download_additional_datasets():
    """Ek sentiment analysis datasetleri indir"""
    
    print("\nğŸ”„ Ek sentiment analysis datasetleri indiriliyor...")
    
    try:
        # Twitter Sentiment Analysis
        kaggle.api.dataset_download_files(
            'kazanova/sentiment140',
            path='./data',
            unzip=True
        )
        print("âœ… Twitter Sentiment140 dataset indirildi!")
        
    except Exception as e:
        print(f"âš ï¸  Twitter dataset indirme baÅŸarÄ±sÄ±z: {e}")
    
    try:
        # Amazon Product Reviews
        kaggle.api.dataset_download_files(
            'bittlingmayer/amazonreviews',
            path='./data',
            unzip=True
        )
        print("âœ… Amazon Reviews dataset indirildi!")
        
    except Exception as e:
        print(f"âš ï¸  Amazon dataset indirme baÅŸarÄ±sÄ±z: {e}")

def check_gpu():
    """GPU durumunu kontrol et"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸš€ GPU: {gpu_name}")
        print(f"ğŸ’¾ GPU Memory: {gpu_memory:.1f} GB")
        return True
    else:
        print("âš ï¸  GPU bulunamadÄ±, CPU kullanÄ±lacak")
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ NLP Sentiment Analysis Projesi")
    print("=" * 60)
    
    # GPU kontrolÃ¼
    gpu_available = check_gpu()
    
    # Ana dataset indir
    df = download_imdb_dataset()
    
    # Ek datasetler indir
    download_additional_datasets()
    
    print("\nğŸ‰ HazÄ±rlÄ±k tamamlandÄ±!")
    print("â–¶ï¸  Åimdi 'python train.py' komutunu Ã§alÄ±ÅŸtÄ±rabilirsiniz")